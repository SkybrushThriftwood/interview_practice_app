2025-11-20 19:58:30,577 [INFO] __main__: User attempting to start interview with job_title=hubabuba ingeneur, type=Behavioral, difficulty=Easy
2025-11-20 19:58:34,205 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 19:58:49,522 [INFO] __main__: User attempting to start interview with job_title=hubabuba ingeneur, type=Behavioral, difficulty=Easy
2025-11-20 19:58:54,599 [INFO] __main__: User attempting to start interview with job_title=hubabuba ingeneur, type=Behavioral, difficulty=Easy
2025-11-20 19:58:55,113 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 19:58:55,297 [INFO] __main__: User attempting to start interview with job_title=hubabuba ingeneur, type=Behavioral, difficulty=Easy
2025-11-20 19:58:55,994 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 19:58:58,392 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 19:59:11,107 [INFO] __main__: User attempting to start interview with job_title=hubabuba ingeneur, type=Behavioral, difficulty=Easy
2025-11-20 19:59:13,581 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:01:49,674 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:01:53,638 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:05:41,476 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:05:46,172 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:35:06,136 [INFO] __main__: User attempting to start interview with job_title=eingener, type=Behavioral, difficulty=Easy
2025-11-20 20:35:09,722 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:35:36,256 [INFO] __main__: User attempting to start interview with job_title=eingener, type=Behavioral, difficulty=Easy
2025-11-20 20:35:38,012 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:38:09,677 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:38:12,857 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:38:19,239 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:38:23,386 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:38:24,272 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:38:27,878 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:38:40,652 [INFO] __main__: User attempting to start interview with job_title=Baker, type=Behavioral, difficulty=Easy
2025-11-20 20:38:42,769 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:38:42,786 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-20 20:38:43,080 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-20 20:38:43,081 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-20 20:38:43,121 [INFO] __main__: Interview started for job_title=Baker
2025-11-20 20:39:06,630 [INFO] __main__: Interview restarted by user
2025-11-20 20:39:31,330 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:39:32,748 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:39:33,005 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:39:36,217 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:39:36,225 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-20 20:39:36,593 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-20 20:39:36,594 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-20 20:39:36,595 [INFO] __main__: Interview started for job_title=baker
2025-11-20 20:39:46,012 [INFO] __main__: Interview restarted by user
2025-11-20 20:40:46,199 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:40:48,126 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:40:57,527 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:40:59,280 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:40:59,980 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:41:01,131 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:41:01,886 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:41:03,430 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:42:39,836 [INFO] __main__: User attempting to start interview with job_title=baker, type=Behavioral, difficulty=Easy
2025-11-20 20:42:41,972 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:42:41,979 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-20 20:42:42,297 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-20 20:42:42,297 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-20 20:42:42,298 [INFO] __main__: Interview started for job_title=baker
2025-11-20 20:42:47,718 [INFO] __main__: Interview restarted by user
2025-11-20 20:42:58,600 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:43:02,555 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:45:01,745 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:45:04,363 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:45:08,015 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:45:09,960 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:45:09,965 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-20 20:45:10,300 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-20 20:45:10,300 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-20 20:45:10,301 [INFO] __main__: Interview started for job_title=engineer
2025-11-20 20:45:20,141 [INFO] __main__: Interview restarted by user
2025-11-20 20:52:45,570 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:52:47,891 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:54:26,138 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:54:28,697 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:54:31,742 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:54:34,108 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:54:42,179 [INFO] __main__: User attempting to start interview with job_title=software engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:54:43,747 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 20:54:43,753 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-20 20:54:44,064 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-20 20:54:44,065 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-20 20:54:44,065 [INFO] __main__: Interview started for job_title=software engineer
2025-11-20 20:56:58,975 [INFO] __main__: User attempting to start interview with job_title=engineer, type=Behavioral, difficulty=Easy
2025-11-20 20:57:01,583 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 21:02:34,176 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Behavioral, difficulty=Easy
2025-11-20 21:02:38,521 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-20 21:02:53,161 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-20 21:02:53,475 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-20 21:02:53,476 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-20 21:02:53,478 [INFO] __main__: Interview started after clarification for job_title=Civil Engineer
2025-11-20 21:03:10,984 [INFO] __main__: Interview restarted by user
2025-11-21 07:50:10,958 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Role-specific, difficulty=Medium
2025-11-21 07:50:18,164 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 07:50:25,894 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'previous_answers'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 58, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'previous_answers'
2025-11-21 07:50:27,465 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-21 07:50:27,466 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[0].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[0].content', 'code': 'invalid_type'}}
2025-11-21 07:50:27,526 [INFO] __main__: Interview started after clarification for job_title=Engineer
2025-11-21 07:53:48,700 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Behavioral, difficulty=Easy
2025-11-21 07:53:54,247 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 07:53:57,545 [ERROR] modules.utils: Error rendering template 'question_prompts.j2': macro 'generate_question' takes no keyword argument 'type'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 60, in get_prompt
    return macro(**kwargs)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\runtime.py", line 759, in __call__
    raise TypeError(
TypeError: macro 'generate_question' takes no keyword argument 'type'
2025-11-21 07:53:58,541 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-21 07:53:58,541 [ERROR] modules.utils: Error in 'openai_call': Error code: 400 - {'error': {'message': "Invalid type for 'input[1].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[1].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 37, in openai_call
    response = client.responses.create(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\resources\responses\responses.py", line 859, in create
    return self._post(
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'input[1].content': expected one of an array of objects or string, but got an object instead.", 'type': 'invalid_request_error', 'param': 'input[1].content', 'code': 'invalid_type'}}
2025-11-21 07:53:58,544 [INFO] __main__: Interview started after clarification for job_title=Engineer
2025-11-21 08:25:23,388 [INFO] __main__: User attempting to start interview with job_title=Engineer, type=Behavioral, difficulty=Easy
2025-11-21 08:25:27,478 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 08:25:39,363 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 08:25:39,364 [INFO] __main__: Interview started after clarification for job_title=software Engineer
2025-11-21 08:25:49,078 [INFO] __main__: Interview restarted by user
2025-11-21 08:28:21,310 [INFO] __main__: Starting interview: job=Software Engineer, type=Behavioral, diff=Easy
2025-11-21 08:28:23,541 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 08:28:27,046 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 08:28:27,047 [INFO] __main__: Interview started for job_title=Software Engineer
2025-11-21 08:32:35,069 [INFO] __main__: Starting interview: job=Engineer, type=Behavioral, diff=Easy
2025-11-21 08:32:38,424 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 08:32:43,366 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 08:32:43,368 [INFO] __main__: Interview started after clarification: Engineer
2025-11-21 08:32:51,312 [INFO] __main__: Interview restarted by user
2025-11-21 09:07:50,597 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 09:07:54,948 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:13:14,995 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 09:13:18,317 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:15:21,696 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 09:15:27,080 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:15:58,168 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:15:58,170 [INFO] __main__: Interview started after clarification: Engineer
2025-11-21 09:25:39,637 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 09:25:44,093 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:26:06,468 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 09:26:10,745 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:26:39,373 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:26:39,375 [INFO] __main__: Interview started after clarification: Engineer
2025-11-21 09:26:47,196 [INFO] __main__: User requesting restart with job_title=Engineer
2025-11-21 09:26:50,243 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:26:50,245 [INFO] __main__: Job title needs clarification: The job title "Engineer" is valid but it is quite broad. For clarification, could you please specify the field of engineering you're in? For example, are you a Software Engineer, Civil Engineer, Mechanical Engineer, etc? This will help us tailor the interview questions to your specific role.
2025-11-21 09:26:57,280 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:28:41,233 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:28:41,238 [INFO] __main__: Answer for Q0: i needed to build a table quickly, but only had scrap wood and no money. so  i used that and made a table
2025-11-21 09:28:41,239 [INFO] __main__: Feedback: Your response is brief and lacks detail. It's good that you were able to use available resources to solve a problem, showing resourcefulness. However, it would be beneficial to elaborate on the process you went through to build the table, the challenges you faced, and how you overcame them. Also, it would be helpful to explain how this situation relates to an engineering challenge.
2025-11-21 09:57:28,549 [INFO] __main__: User requesting restart with job_title=Engineerer
2025-11-21 09:57:35,091 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:57:35,092 [INFO] __main__: Job title needs clarification: The job title "Engineerer" is unusual and it seems like there might have been a spelling mistake. Could you please provide clarification? Did you mean "Engineer"? There are various specializations such as "Software Engineer", "Civil Engineer", "Mechanical Engineer", etc. Your clarification will help us to proceed with the interview more accurately.
2025-11-21 09:58:02,134 [INFO] __main__: User requesting restart with job_title=software engineer
2025-11-21 09:58:04,597 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:58:06,668 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:58:06,671 [INFO] __main__: Interview restarted for job_title=software engineer
2025-11-21 09:58:17,171 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:58:17,174 [INFO] __main__: Answer for Q0: i needed to build a table quickly, but only had scrap wood and no money. so  i used that and made a table
2025-11-21 09:58:17,174 [INFO] __main__: Feedback: Your answer does not address the question asked. The question was about a complex programming problem, but your response discusses a physical construction project. It's important to read the question carefully and ensure your answer is relevant.
2025-11-21 09:59:23,178 [INFO] __main__: User requesting restart with job_title=software engineer
2025-11-21 09:59:24,791 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:59:26,387 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 09:59:26,389 [INFO] __main__: Interview restarted for job_title=software engineer
2025-11-21 11:03:21,958 [INFO] __main__: User requesting restart with job_title=software engineer
2025-11-21 11:03:24,597 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 11:03:27,406 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 11:03:27,408 [INFO] __main__: Interview restarted for job_title=software engineer
2025-11-21 11:23:39,558 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 11:23:45,481 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 11:23:55,275 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 11:23:55,277 [INFO] __main__: Interview started after clarification: Eingener
2025-11-21 11:50:17,933 [INFO] __main__: Starting interview: job=Engineer, type=Behavioral, diff=Easy
2025-11-21 11:50:21,186 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-21 11:52:20,619 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Medium
2025-11-21 11:52:20,620 [INFO] __main__: Interview started for job_title=Eingener
2025-11-21 11:52:33,269 [INFO] __main__: User requesting restart with job_title=Wizard of Light
2025-11-21 11:52:33,269 [INFO] __main__: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-21 11:52:45,405 [INFO] __main__: Answer for Q1: Tom

2025-11-21 11:52:45,405 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 11:56:57,376 [INFO] __main__: Answer for Q2: as
2025-11-21 11:56:57,377 [INFO] __main__: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-21 12:01:40,721 [INFO] __main__: Starting interview: job=Wizard of Light, type=Behavioral, diff=Easy
2025-11-21 12:01:44,991 [INFO] __main__: Interview started after clarification: Wizard of Light
2025-11-21 12:01:48,008 [INFO] __main__: Answer for Q1: asd
2025-11-21 12:01:48,008 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:01:53,873 [INFO] __main__: Answer for Q2: dasdasd
2025-11-21 12:01:53,873 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:01:56,348 [INFO] __main__: Answer for Q3: asdasd
2025-11-21 12:01:56,349 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:01:59,212 [INFO] __main__: Answer for Q4: asdasd
2025-11-21 12:01:59,213 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:02:02,138 [INFO] __main__: Answer for Q5: asdasdasd
2025-11-21 12:02:02,138 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:13:41,075 [INFO] __main__: Starting interview: job=Engineer, type=Behavioral, diff=Easy
2025-11-21 12:13:41,076 [INFO] __main__: Interview started for job_title=Engineer
2025-11-21 12:14:15,322 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 12:14:15,323 [INFO] __main__: Interview started for job_title=Eingener
2025-11-21 12:40:03,341 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 12:40:03,342 [INFO] __main__: Interview started for job_title=Eingener
2025-11-21 12:49:12,981 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-21 12:49:12,983 [INFO] __main__: Interview started for job_title=Eingener
2025-11-21 12:51:02,403 [INFO] __main__: Starting interview: job=asdasd, type=Behavioral, diff=Easy
2025-11-21 12:51:02,403 [INFO] __main__: Interview started for job_title=asdasd
2025-11-21 12:51:04,377 [INFO] __main__: Answer for Q1: asdasd
2025-11-21 12:51:04,378 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:51:07,694 [INFO] __main__: Answer for Q2: asfasv
2025-11-21 12:51:07,694 [INFO] __main__: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-21 12:56:13,228 [INFO] __main__: Answer for Q3: asdfasf

2025-11-21 12:56:13,228 [INFO] __main__: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-21 12:56:14,734 [INFO] __main__: Answer for Q4: asfasf
2025-11-21 12:56:14,735 [INFO] __main__: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-21 12:56:16,261 [INFO] __main__: Answer for Q5: asfasf
2025-11-21 12:56:16,261 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-21 12:56:17,879 [INFO] __main__: Answer for Q6: asfasf
2025-11-21 12:56:17,879 [INFO] __main__: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-21 12:56:19,601 [INFO] __main__: Answer for Q7: asfasfasf
2025-11-21 12:56:19,601 [INFO] __main__: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-21 12:56:22,247 [INFO] __main__: Answer for Q8: asfasfasf
2025-11-21 12:56:22,247 [INFO] __main__: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-21 12:56:24,341 [INFO] __main__: Answer for Q9: asfasfas
2025-11-21 12:56:24,341 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 07:47:44,413 [INFO] __main__: Starting interview: job=Eingener, type=Behavioral, diff=Easy
2025-11-24 07:47:44,415 [INFO] __main__: Interview started for job_title=Eingener
2025-11-24 07:47:48,801 [INFO] __main__: Answer for Q1: asdasd
2025-11-24 07:47:48,801 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 07:47:55,059 [INFO] __main__: Answer for Q2: asd
2025-11-24 07:47:55,059 [INFO] __main__: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 07:47:56,353 [INFO] __main__: Answer for Q3: asdsad
2025-11-24 07:47:56,353 [INFO] __main__: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 07:47:57,862 [INFO] __main__: Answer for Q4: asdsad
2025-11-24 07:47:57,863 [INFO] __main__: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 07:47:59,324 [INFO] __main__: Answer for Q5: asdasd
2025-11-24 07:47:59,325 [INFO] __main__: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 07:48:00,728 [INFO] __main__: Answer for Q6: asdsad
2025-11-24 07:48:00,729 [INFO] __main__: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 07:48:02,349 [INFO] __main__: Answer for Q7: asdsad
2025-11-24 07:48:02,349 [INFO] __main__: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 07:48:04,938 [INFO] __main__: Answer for Q8: asdasd
2025-11-24 07:48:04,938 [INFO] __main__: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 08:09:12,588 [INFO] __main__: Starting interview: job=Wizard of Light, type=Behavioral, diff=Hard
2025-11-24 08:09:14,206 [INFO] __main__: Interview started after clarification: Wizard of Light
2025-11-24 08:18:50,779 [INFO] modules.ui_main_screen: Interview started for job_title=Eingener
2025-11-24 08:18:59,849 [INFO] __main__: User requesting restart with job_title=Eingener
2025-11-24 08:18:59,850 [INFO] __main__: Interview restarted for job_title=Eingener
2025-11-24 08:47:24,555 [INFO] modules.ui_main_screen: Interview started for job_title=asdasd
2025-11-24 08:47:33,060 [INFO] __main__: User requesting restart with job_title=Wizard of Light
2025-11-24 08:47:33,061 [INFO] __main__: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 08:47:59,292 [INFO] modules.ui_main_screen: Interview started after clarification: Wizard of Lightas
2025-11-24 08:48:03,375 [INFO] __main__: User requesting restart with job_title=Wizard of Light
2025-11-24 08:48:03,376 [INFO] __main__: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 09:05:50,007 [INFO] modules.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 09:05:58,549 [INFO] modules.ui_sidebar: User requesting restart with job_title=Wizard of Light
2025-11-24 09:05:58,550 [INFO] modules.ui_sidebar: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 09:06:04,836 [INFO] modules.ui_sidebar: User requesting restart with job_title=Wizard of Light
2025-11-24 09:06:04,836 [INFO] modules.ui_sidebar: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 09:17:00,242 [INFO] modules.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 09:17:02,215 [INFO] modules.ui_interview: Answer for Q1: asdasd
2025-11-24 09:17:02,215 [INFO] modules.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 09:17:03,907 [INFO] modules.ui_interview: Answer for Q2: asdasd
2025-11-24 09:17:03,907 [INFO] modules.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 09:17:07,621 [INFO] modules.ui_interview: Answer for Q3: asdasd
2025-11-24 09:17:07,621 [INFO] modules.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 09:17:15,725 [INFO] modules.ui_sidebar: User requesting restart with job_title=asdasdasd
2025-11-24 09:17:15,726 [INFO] modules.ui_sidebar: Interview restarted for job_title=asdasdasd
2025-11-24 09:26:22,151 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Eingener
2025-11-24 10:04:32,950 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=asdasd
2025-11-24 10:04:32,951 [INFO] modules.ui.ui_sidebar: Interview restarted for job_title=asdasd
2025-11-24 10:04:53,471 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 10:13:04,215 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 10:13:12,290 [INFO] modules.ui.ui_interview: Answer for Q1: asdads
2025-11-24 10:13:12,290 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:13:14,530 [INFO] modules.ui.ui_interview: Answer for Q2: asdasd
2025-11-24 10:13:14,530 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 10:13:18,719 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard of Light
2025-11-24 10:13:18,719 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 10:13:31,092 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard of Light
2025-11-24 10:13:31,092 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 10:14:33,847 [INFO] modules.ui.ui_start_screen: Interview started for job_title=asd
2025-11-24 10:14:41,053 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Eingener
2025-11-24 10:15:14,580 [INFO] modules.ui.ui_start_screen: Interview started for job_title=asdasd
2025-11-24 10:17:39,463 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Eingener
2025-11-24 10:22:36,052 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 10:22:43,032 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=asdasd
2025-11-24 10:26:22,199 [INFO] modules.ui.ui_start_screen: Interview started for job_title=asdasdasdasdasd
2025-11-24 10:26:24,218 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-24 10:26:24,218 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:26:51,117 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard of Lightas
2025-11-24 10:26:57,379 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard of Light
2025-11-24 10:26:57,380 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-24 10:31:48,358 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 10:34:17,045 [INFO] modules.ui.ui_interview: Answer for Q5: asfasf
2025-11-24 10:34:17,045 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:34:19,703 [INFO] modules.ui.ui_interview: Answer for Q6: asfasfas
2025-11-24 10:34:19,703 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 10:34:24,095 [INFO] modules.ui.ui_interview: Answer for Q7: asfasfa
2025-11-24 10:34:24,095 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 10:34:26,256 [INFO] modules.ui.ui_interview: Answer for Q8: asfasfas
2025-11-24 10:34:26,257 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 10:34:28,885 [INFO] modules.ui.ui_interview: Answer for Q9: asfasfas
2025-11-24 10:34:28,885 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:34:32,196 [INFO] modules.ui.ui_interview: Answer for Q10: asfasfas
2025-11-24 10:34:32,197 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 10:34:37,807 [INFO] modules.ui.ui_interview: Answer for Q11: asfasfasf
2025-11-24 10:34:37,807 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 10:34:43,067 [INFO] modules.ui.ui_interview: Answer for Q12: asfasfasfas
2025-11-24 10:34:43,068 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 10:34:45,030 [INFO] modules.ui.ui_interview: Answer for Q13: asfasfasf
2025-11-24 10:34:45,030 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:37:11,458 [INFO] modules.ui.ui_interview: Answer for Q14: asdasdas
2025-11-24 10:37:11,458 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 10:37:13,145 [INFO] modules.ui.ui_interview: Answer for Q15: asdasdas
2025-11-24 10:37:13,145 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 10:37:15,881 [INFO] modules.ui.ui_interview: Answer for Q16: sadasd
2025-11-24 10:37:15,881 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 10:37:37,615 [INFO] modules.ui.ui_start_screen: Interview started for job_title=asdasd
2025-11-24 10:37:39,425 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-24 10:37:39,426 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:37:40,726 [INFO] modules.ui.ui_interview: Answer for Q2: asdasd
2025-11-24 10:37:40,726 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 10:37:41,880 [INFO] modules.ui.ui_interview: Answer for Q3: a
2025-11-24 10:37:41,880 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 10:37:43,111 [INFO] modules.ui.ui_interview: Answer for Q4: a
2025-11-24 10:37:43,111 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 10:37:44,154 [INFO] modules.ui.ui_interview: Answer for Q5: a
2025-11-24 10:37:44,155 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 10:37:46,486 [INFO] modules.ui.ui_interview: Answer for Q6: a
2025-11-24 10:37:46,486 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 10:37:51,218 [INFO] modules.ui.ui_interview: Answer for Q7: a
2025-11-24 10:37:51,219 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:39:57,258 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 11:40:00,355 [INFO] modules.ui.ui_interview: Answer for Q1: asd
2025-11-24 11:40:00,356 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:40:01,663 [INFO] modules.ui.ui_interview: Answer for Q2: asd
2025-11-24 11:40:01,664 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 11:40:02,890 [INFO] modules.ui.ui_interview: Answer for Q3: asd
2025-11-24 11:40:02,891 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:40:04,080 [INFO] modules.ui.ui_interview: Answer for Q4: asd
2025-11-24 11:40:04,080 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 11:40:05,773 [INFO] modules.ui.ui_interview: Answer for Q5: asd
2025-11-24 11:40:05,774 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:40:07,180 [INFO] modules.ui.ui_interview: Answer for Q6: asd
2025-11-24 11:40:07,180 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 11:40:08,443 [INFO] modules.ui.ui_interview: Answer for Q7: asd
2025-11-24 11:40:08,444 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:40:11,759 [INFO] modules.ui.ui_interview: Answer for Q8: asd

2025-11-24 11:40:11,759 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 11:40:48,608 [INFO] modules.ui.ui_interview: Answer for Q9: asdasd

2025-11-24 11:40:48,608 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:41:15,190 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Eingener
2025-11-24 11:41:20,289 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-24 11:41:20,290 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:41:24,025 [INFO] modules.ui.ui_interview: Answer for Q2: asd
2025-11-24 11:41:24,026 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 11:41:25,926 [INFO] modules.ui.ui_interview: Answer for Q3: asd
2025-11-24 11:41:25,927 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:45:05,345 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Eingener
2025-11-24 11:45:08,879 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-24 11:45:08,880 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:45:10,627 [INFO] modules.ui.ui_interview: Answer for Q2: asdasd
2025-11-24 11:45:10,627 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 11:45:12,291 [INFO] modules.ui.ui_interview: Answer for Q3: asdasd
2025-11-24 11:45:12,292 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:45:13,803 [INFO] modules.ui.ui_interview: Answer for Q4: asdasd
2025-11-24 11:45:13,803 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 11:45:14,917 [INFO] modules.ui.ui_interview: Answer for Q5: asd
2025-11-24 11:45:14,917 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:45:16,123 [INFO] modules.ui.ui_interview: Answer for Q6: asd
2025-11-24 11:45:16,123 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 11:45:17,692 [INFO] modules.ui.ui_interview: Answer for Q7: asd
2025-11-24 11:45:17,692 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:45:21,064 [INFO] modules.ui.ui_interview: Answer for Q8: asd
2025-11-24 11:45:21,064 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 11:47:00,270 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 11:47:02,884 [INFO] modules.ui.ui_interview: Answer for Q1: sdfsdf
2025-11-24 11:47:02,884 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 11:47:04,376 [INFO] modules.ui.ui_interview: Answer for Q2: sdfsdf
2025-11-24 11:47:04,376 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 11:47:12,209 [INFO] modules.ui.ui_interview: Answer for Q3: sdfsdfsdf
2025-11-24 11:47:12,210 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 11:47:16,256 [INFO] modules.ui.ui_interview: Answer for Q4:     job_title, question_type, difficulty, should_restart = display_sidebar()
    if should_restart:
        handle_sidebar_restart()

    # Main interview content
    st.header(f"Interview Practice for: {st.session_state.job_title}")
    st.write(f"Question Type: **{st.session_state.question_type}**, Difficulty: **{st.session_state.difficulty}**")

    # Chat container
    chat_container = st.container()
    with chat_container:
        for i, q in enumerate(st.session_state.questions):
            st.markdown(f"**Q{i+1}: {q}**")
            if i < len(st.session_state.answers):
                st.markdown(f"**A{i+1}:** {st.session_state.answers[i]}")
            if i < len(st.session_state.feedbacks):
                st.markdown(f"**Feedback:** {st.session_state.feedbacks[i]}")
        st.markdown('<div id="bottom"></div>', unsafe_allow_html=True)
    st.markdown('<script>document.getElementById("bottom").scrollIntoView({behavior: "smooth"});</script>', unsafe_allow_html=True)

    # Answer input
    answer_key = f"answer_input_{st.session_state.current_question_index}"
    initial_value = st.session_state.get(answer_key, "")
    user_answer = st.text_area("Your Answer", value=initial_value, key=answer_key, height=100) or ""

    if st.button("Submit Answer"):
        if not user_answer.strip():
            st.error("Please enter an answer before submitting.")
        else:
            feedback, next_question = evaluate_answer_and_generate_next(user_answer)
            st.session_state.answers.append(user_answer)
            st.session_state.feedbacks.append(feedback)
2025-11-24 11:47:16,257 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:07:03,350 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-24 12:07:05,444 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-24 12:07:05,445 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:07:06,612 [INFO] modules.ui.ui_interview: Answer for Q2: asd
2025-11-24 12:07:06,612 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:07:07,870 [INFO] modules.ui.ui_interview: Answer for Q3: asd
2025-11-24 12:07:07,871 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:07:09,404 [INFO] modules.ui.ui_interview: Answer for Q4: asd
2025-11-24 12:07:09,405 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:07:12,014 [INFO] modules.ui.ui_interview: Answer for Q5: asd
2025-11-24 12:07:12,015 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:07:13,247 [INFO] modules.ui.ui_interview: Answer for Q6: asd
2025-11-24 12:07:13,247 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:07:14,673 [INFO] modules.ui.ui_interview: Answer for Q7: asd
2025-11-24 12:07:14,673 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:07:15,977 [INFO] modules.ui.ui_interview: Answer for Q8: asd
2025-11-24 12:07:15,978 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:07:18,774 [INFO] modules.ui.ui_interview: Answer for Q9: asd
2025-11-24 12:07:18,775 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:07:22,915 [INFO] modules.ui.ui_interview: Answer for Q10: asd
2025-11-24 12:07:22,916 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:07:25,100 [INFO] modules.ui.ui_interview: Answer for Q11: asd
2025-11-24 12:07:25,100 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:08:24,143 [INFO] modules.ui.ui_start_screen: Interview started for job_title=asdasd
2025-11-24 12:08:25,755 [INFO] modules.ui.ui_interview: Answer for Q1: asd
2025-11-24 12:08:25,756 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:08:26,836 [INFO] modules.ui.ui_interview: Answer for Q2: asd
2025-11-24 12:08:26,836 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:08:28,475 [INFO] modules.ui.ui_interview: Answer for Q3: s
2025-11-24 12:08:28,475 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:08:30,039 [INFO] modules.ui.ui_interview: Answer for Q4: s
2025-11-24 12:08:30,039 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:08:31,065 [INFO] modules.ui.ui_interview: Answer for Q5: s
2025-11-24 12:08:31,066 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:08:32,159 [INFO] modules.ui.ui_interview: Answer for Q6: s
2025-11-24 12:08:32,159 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:08:33,743 [INFO] modules.ui.ui_interview: Answer for Q7: s
2025-11-24 12:08:33,743 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:08:35,156 [INFO] modules.ui.ui_interview: Answer for Q8: s
2025-11-24 12:08:35,157 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:08:37,143 [INFO] modules.ui.ui_interview: Answer for Q9: s
2025-11-24 12:08:37,143 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:09:41,119 [INFO] modules.ui.ui_start_screen: Interview started for job_title=asd
2025-11-24 12:09:42,598 [INFO] modules.ui.ui_interview: Answer for Q1: asd
2025-11-24 12:09:42,598 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:09:44,401 [INFO] modules.ui.ui_interview: Answer for Q2: asd
2025-11-24 12:09:44,402 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:09:45,559 [INFO] modules.ui.ui_interview: Answer for Q3: asd
2025-11-24 12:09:45,559 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:09:46,561 [INFO] modules.ui.ui_interview: Answer for Q4: s
2025-11-24 12:09:46,561 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:09:47,873 [INFO] modules.ui.ui_interview: Answer for Q5: s
2025-11-24 12:09:47,873 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:09:49,060 [INFO] modules.ui.ui_interview: Answer for Q6: s
2025-11-24 12:09:49,060 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:09:50,070 [INFO] modules.ui.ui_interview: Answer for Q7: s
2025-11-24 12:09:50,071 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:09:51,272 [INFO] modules.ui.ui_interview: Answer for Q8: s
2025-11-24 12:09:51,273 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:09:53,210 [INFO] modules.ui.ui_interview: Answer for Q9: s
2025-11-24 12:09:53,210 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:11:09,941 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=asd
2025-11-24 12:15:04,696 [INFO] modules.ui.ui_interview: Answer for Q1: asdas
2025-11-24 12:15:04,696 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:15:05,825 [INFO] modules.ui.ui_interview: Answer for Q2: as
2025-11-24 12:15:05,825 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:15:07,015 [INFO] modules.ui.ui_interview: Answer for Q3: as
2025-11-24 12:15:07,015 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:15:08,775 [INFO] modules.ui.ui_interview: Answer for Q4: as
2025-11-24 12:15:08,775 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:15:10,245 [INFO] modules.ui.ui_interview: Answer for Q5: as
2025-11-24 12:15:10,245 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:15:11,488 [INFO] modules.ui.ui_interview: Answer for Q6: as
2025-11-24 12:15:11,489 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:15:12,715 [INFO] modules.ui.ui_interview: Answer for Q7: as
2025-11-24 12:15:12,715 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:15:14,119 [INFO] modules.ui.ui_interview: Answer for Q8: as
2025-11-24 12:15:14,119 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:20:49,632 [INFO] modules.ui.ui_interview: Answer for Q9: asdasd
2025-11-24 12:20:49,632 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:20:51,613 [INFO] modules.ui.ui_interview: Answer for Q10: asdasd
2025-11-24 12:20:51,614 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:20:53,891 [INFO] modules.ui.ui_interview: Answer for Q11: asdasd
2025-11-24 12:20:53,891 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:22:12,899 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=asd
2025-11-24 12:22:14,231 [INFO] modules.ui.ui_interview: Answer for Q1: a
2025-11-24 12:22:14,231 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:22:15,292 [INFO] modules.ui.ui_interview: Answer for Q2: s
2025-11-24 12:22:15,292 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:22:16,361 [INFO] modules.ui.ui_interview: Answer for Q3: a
2025-11-24 12:22:16,362 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:22:17,716 [INFO] modules.ui.ui_interview: Answer for Q4: s
2025-11-24 12:22:17,716 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:22:18,700 [INFO] modules.ui.ui_interview: Answer for Q5: a
2025-11-24 12:22:18,700 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-24 12:22:19,744 [INFO] modules.ui.ui_interview: Answer for Q6: a
2025-11-24 12:22:19,745 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-24 12:22:20,971 [INFO] modules.ui.ui_interview: Answer for Q7: s
2025-11-24 12:22:20,971 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-24 12:22:22,173 [INFO] modules.ui.ui_interview: Answer for Q8: a
2025-11-24 12:22:22,174 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-24 12:22:24,865 [INFO] modules.ui.ui_interview: Answer for Q9: s
2025-11-24 12:22:24,865 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-25 12:05:24,644 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-25 12:05:29,318 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-25 12:05:29,318 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-25 12:05:30,818 [INFO] modules.ui.ui_interview: Answer for Q2: asdasd
2025-11-25 12:05:30,819 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-25 12:05:31,951 [WARNING] modules.interview_logic: Failed to parse JSON from summary. Returning raw text.
2025-11-25 14:32:27,990 [WARNING] modules.interview_logic: Failed to parse JSON from summary. Returning raw text.
2025-11-25 14:32:32,856 [WARNING] modules.interview_logic: Failed to parse JSON from summary. Returning raw text.
2025-11-25 14:32:32,942 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard of Lights
2025-11-25 14:32:32,980 [WARNING] modules.interview_logic: Failed to parse JSON from summary. Returning raw text.
2025-11-25 14:33:20,970 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Eingener
2025-11-25 15:11:35,526 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=asdasd
2025-11-25 15:11:37,545 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=asdasd
2025-11-25 15:11:53,879 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-25 15:12:15,177 [INFO] modules.ui.ui_interview: Answer for Q1: asd
2025-11-25 15:12:15,177 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-25 15:12:18,539 [INFO] modules.ui.ui_interview: Answer for Q2: asd
2025-11-25 15:12:18,539 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-25 15:17:09,460 [INFO] modules.ui.ui_interview: Answer for Q3: wef
2025-11-25 15:17:09,461 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-25 15:17:10,831 [INFO] modules.ui.ui_interview: Answer for Q4: wef
2025-11-25 15:17:10,831 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-25 15:17:12,127 [INFO] modules.ui.ui_interview: Answer for Q5: wef
2025-11-25 15:17:12,128 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-25 15:17:13,344 [INFO] modules.ui.ui_interview: Answer for Q6: wef
2025-11-25 15:17:13,344 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Solid response. Could give more examples.
2025-11-25 15:17:15,120 [INFO] modules.ui.ui_interview: Answer for Q7: wef
2025-11-25 15:17:15,121 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Excellent! Well-structured answer.
2025-11-25 15:17:16,514 [INFO] modules.ui.ui_interview: Answer for Q8: wef
2025-11-25 15:17:16,514 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Nice! Consider elaborating on impact.
2025-11-25 15:19:01,269 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard of Light
2025-11-25 15:19:01,270 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Mock Clarification: This job title seems unusual. Please confirm.
2025-11-25 15:20:28,611 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-25 15:21:07,848 [INFO] modules.ui.ui_interview: Answer for Q1: asdasdasd
2025-11-25 15:21:07,849 [INFO] modules.ui.ui_interview: Feedback: Mock Feedback: Good answer! Try to be more concise.
2025-11-26 09:21:13,547 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-26 10:03:18,770 [ERROR] modules.validation: Failed to load base instructions for job title validation.
2025-11-26 10:21:17,244 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 10:21:33,277 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 74, in generate_next_question
    sys_instructions = load_prompt("system/question_generator.j2")
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 10:21:33,279 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Software Engineer
2025-11-26 10:31:45,553 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 10:32:03,485 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 74, in generate_next_question
    sys_instructions = load_prompt("system/question_generator.j2")
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 10:32:03,488 [INFO] modules.ui.ui_start_screen: Interview started after clarification: retail clerk
2025-11-26 10:48:56,733 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 10:48:56,738 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 74, in generate_next_question
    sys_instructions = load_prompt("system/question_generator.j2")
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 10:48:56,741 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-26 10:48:56,741 [INFO] modules.ui.ui_interview: Feedback: Feedback could not be parsed.
2025-11-26 10:52:50,803 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 74, in generate_next_question
    sys_instructions = load_prompt("system/question_generator.j2")
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 10:53:00,272 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 10:53:00,274 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 74, in generate_next_question
    sys_instructions = load_prompt("system/question_generator.j2")
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 10:53:00,276 [INFO] modules.ui.ui_interview: Answer for Q2: because of the deer.
2025-11-26 10:53:00,276 [INFO] modules.ui.ui_interview: Feedback: Feedback could not be parsed.
2025-11-26 12:22:57,455 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 12:23:06,798 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 81, in generate_next_question
    sys_instructions = load_prompt(SYSTEM_PROMPTS["question_generator"])
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 12:23:06,801 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Civil Engineer
2025-11-26 12:51:51,111 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 12:52:00,419 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 150, in generate_next_question
    sys_instructions = load_prompt(SYSTEM_PROMPTS["question_generator"])
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 12:52:00,423 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-26 13:47:10,260 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 13:47:10,343 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-26 13:47:10,443 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 141, in generate_next_question
    sys_instructions = load_prompt(SYSTEM_PROMPTS["question_generator"])
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 13:47:29,752 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Eingener
2025-11-26 13:47:35,405 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 13:47:35,419 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Clarification needed: The job title "Eingener" is not recognizable. It could be a typo. Did you mean "Engineer"? If so, please specify the type of engineer (e.g., Mechanical Engineer, Software Engineer, Civil Engineer).
2025-11-26 13:47:37,718 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 141, in generate_next_question
    sys_instructions = load_prompt(SYSTEM_PROMPTS["question_generator"])
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 14:24:35,559 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:24:38,345 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Wizard of Light
2025-11-26 14:24:38,440 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 131, in generate_next_question
    sys_instructions = load_prompt(SYSTEM_PROMPTS["question_generator"])
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 14:25:45,270 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Wizard sasd Light
2025-11-26 14:25:49,976 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:25:49,977 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Clarification needed: The job title "Wizard sasd Light" is not recognizable or specific. It seems like there might be a typo or misspelling. Could you mean a role in a specific industry or field, such as "Lighting Wizard" in the entertainment or event industry, or "Wizard of Light" in a creative or design field? Please provide a clearer job title.
2025-11-26 14:25:51,600 [ERROR] modules.utils: Error in 'generate_next_question': 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 131, in generate_next_question
    sys_instructions = load_prompt(SYSTEM_PROMPTS["question_generator"])
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'system/question_generator.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 14:35:05,500 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:35:05,508 [ERROR] modules.interview_logic: Failed to parse evaluation JSON: Expecting value: line 1 column 1 (char 0)
2025-11-26 14:35:05,508 [INFO] modules.ui.ui_interview: Answer for Q1: asdasd
2025-11-26 14:35:05,509 [INFO] modules.ui.ui_interview: Feedback: Error parsing model response.
2025-11-26 14:35:17,229 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:35:46,344 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:35:46,430 [INFO] modules.ui.ui_start_screen: Interview started for job_title=software engineer
2025-11-26 14:35:46,514 [ERROR] modules.utils: Error in 'generate_next_question': 'question/base_instructions.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 134, in generate_next_question
    prompt_content = build_prompt(
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 84, in build_prompt
    base = load_prompt_cached(f"{category}/{base_instructions}", **kwargs_for_cache)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 71, in load_prompt_cached
    return load_prompt(template_name, kwargs_tuple=tuple(sorted(kwargs.items())))
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'question/base_instructions.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 14:45:16,247 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:45:16,320 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-26 14:45:16,408 [ERROR] modules.utils: Error in 'generate_next_question': 'question/base_instructions.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 22, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\interview_logic.py", line 134, in generate_next_question
    prompt_content = build_prompt(
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 84, in build_prompt
    base = load_prompt_cached(f"{category}/{base_instructions}", **kwargs_for_cache)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 71, in load_prompt_cached
    return load_prompt(template_name, kwargs_tuple=tuple(sorted(kwargs.items())))
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 66, in load_prompt
    template = env.get_template(template_name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\jinja2\loaders.py", line 209, in get_source
    raise TemplateNotFound(
jinja2.exceptions.TemplateNotFound: 'question/base_instructions.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-11-26 14:45:16,411 [INFO] modules.ui.ui_interview: First question generated: None
2025-11-26 14:49:48,035 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:49:48,119 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-26 14:49:50,743 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:49:50,745 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you describe a time when you had to solve a complex problem and how you approached it?'
2025-11-26 14:50:30,741 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=dispatcher
2025-11-26 14:50:34,076 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:50:37,235 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-26 14:50:37,236 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you explain how you would approach debugging a complex system that you are not familiar with?'
2025-11-27 08:15:54,430 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:15:54,512 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-27 08:15:57,594 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:15:57,595 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you explain how you would approach debugging a complex system that is not behaving as expected?'
2025-11-27 08:16:08,472 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title= accountant
2025-11-27 08:16:10,915 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:16:14,161 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:16:14,162 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you describe a situation where you had to use your problem-solving skills to fix a critical bug in the code?'
2025-11-27 08:16:38,284 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:16:38,286 [ERROR] modules.interview_logic: Failed to parse evaluation JSON: Expecting value: line 1 column 1 (char 0)
2025-11-27 08:23:17,598 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:23:17,677 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-27 08:23:20,907 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:23:20,908 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you describe a time when you had to solve a complex problem and how you approached it?'
2025-11-27 08:23:26,407 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Accountant
2025-11-27 08:23:29,421 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:23:31,879 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:23:34,426 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:23:34,427 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you explain how you would approach debugging a complex system that is not behaving as expected?'
2025-11-27 08:43:12,735 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:43:12,820 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-27 08:43:15,290 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:43:15,291 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you describe a situation where you had to use your problem-solving skills to fix a critical bug in the code?'
2025-11-27 08:43:36,743 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=accountant
2025-11-27 08:43:39,605 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:43:42,053 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:43:42,055 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you explain how you would approach debugging a complex system that is not behaving as expected?'
2025-11-27 08:44:43,691 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:44:43,693 [ERROR] modules.interview_logic: Failed to parse evaluation JSON: Expecting value: line 1 column 1 (char 0)
2025-11-27 08:52:40,189 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:52:40,276 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Accountant
2025-11-27 08:52:42,732 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:52:42,734 [INFO] modules.ui.ui_interview: First question generated: 'As a software engineer, can you describe a situation where you had to use your problem-solving skills to debug a complex piece of code?'
2025-11-27 08:57:26,121 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Engineer
2025-11-27 08:57:29,973 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:57:29,974 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Clarification needed: The job title "Engineer" is too broad as it encompasses a wide range of fields. Please specify the type of engineer. For example, are you a Civil Engineer, Mechanical Engineer, or Software Engineer?
2025-11-27 08:57:42,215 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 08:59:59,040 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Engineer clerk
2025-11-27 09:00:02,317 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:00:02,319 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Clarification needed: The job title "Engineer clerk" is not clear. Are you referring to an Engineering Clerk, who assists engineers by performing administrative tasks? Or perhaps a Clerk Engineer, a term sometimes used in the railway industry? Please provide more specific information.
2025-11-27 09:00:30,473 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:02,750 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=baker
2025-11-27 09:01:05,188 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:07,577 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:07,579 [INFO] modules.ui.ui_interview: First question generated: 'What are the key factors to consider when scaling a small batch recipe to a large production scale, and how would you ensure consistency in taste and quality?'
2025-11-27 09:01:39,678 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=joiner
2025-11-27 09:01:42,121 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:44,567 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:44,569 [INFO] modules.ui.ui_interview: First question generated: "Can you describe a complex joinery project you've worked on where you had to use advanced techniques to overcome challenges, and how did you ensure the quality and precision of your work?"
2025-11-27 09:01:52,671 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=joiner
2025-11-27 09:01:55,141 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:58,762 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:01:58,763 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to handle a particularly difficult client or customer while working on a joinery project? How did you manage the situation and what was the outcome?'
2025-11-27 09:02:52,084 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=fahrdienstleiter
2025-11-27 09:02:54,572 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:02:57,052 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:02:57,053 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a situation where you had to make a critical decision under extreme pressure, and how did you ensure the safety and efficiency of the rail operations?'
2025-11-27 09:04:26,917 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-27 09:04:26,925 [ERROR] modules.interview_logic: Failed to parse evaluation JSON: Expecting value: line 1 column 1 (char 0)
2025-11-28 08:52:00,123 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 08:52:00,206 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Dispatcher
2025-11-28 08:52:03,343 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 08:52:03,345 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a situation where you had to make a quick decision under pressure?'
2025-11-28 08:53:03,949 [ERROR] modules.utils: Error in 'openai_call': RetryError[<Future at 0x1777512bb20 state=finished raised TypeError>]
Traceback (most recent call last):
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 101, in _call_openai
    response = _client.responses.create(**request_kwargs)
TypeError: Responses.create() got an unexpected keyword argument 'response_format'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 24, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\modules\utils.py", line 136, in openai_call
    return _call_openai(sys_instructions, prompt_text, temperature, response_format)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "C:\Users\thoma\AppData\Local\pypoetry\Cache\virtualenvs\interview-practice-app--g2Z2Tjt-py3.10\lib\site-packages\tenacity\__init__.py", line 421, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x1777512bb20 state=finished raised TypeError>]
2025-11-28 09:19:37,094 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:19:37,174 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Dispatcher
2025-11-28 09:19:38,150 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:19:40,923 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:19:43,189 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:19:43,190 [ERROR] modules.utils: Error in 'openai_call': RetryError[<Future at 0x24ca6c14820 state=finished raised BadRequestError>]
2025-11-28 09:19:43,190 [INFO] modules.ui.ui_interview: First question generated: 'Could not generate question. Please try again.'
2025-11-28 09:20:12,574 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Dispatcher
2025-11-28 09:20:16,728 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:20:17,015 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:20:19,623 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:20:21,880 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:20:21,881 [ERROR] modules.utils: Error in 'openai_call': RetryError[<Future at 0x24ca659a680 state=finished raised BadRequestError>]
2025-11-28 09:20:21,881 [INFO] modules.ui.ui_interview: First question generated: 'Could not generate question. Please try again.'
2025-11-28 09:23:07,230 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Dispatcher
2025-11-28 09:23:09,763 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:23:10,553 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:23:12,832 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:23:15,070 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:23:15,071 [ERROR] modules.utils: Error in 'openai_call': RetryError[<Future at 0x24ca64a61d0 state=finished raised BadRequestError>]
2025-11-28 09:23:15,071 [INFO] modules.ui.ui_interview: First question generated: 'Could not generate question. Please try again.'
2025-11-28 09:27:39,283 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:27:39,476 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Dispatcher
2025-11-28 09:27:39,805 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:27:42,033 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:27:44,250 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-11-28 09:27:44,251 [ERROR] modules.utils: Error in 'openai_call': RetryError[<Future at 0x25e0cda5c00 state=finished raised BadRequestError>]
2025-11-28 09:27:44,251 [INFO] modules.ui.ui_interview: First question generated: 'Could not generate question. Please try again.'
2025-11-28 09:33:11,512 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Dispatcher
2025-11-28 09:33:13,930 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:33:18,008 [ERROR] modules.utils: Error in 'openai_call': RetryError[<Future at 0x25e0cd5ab90 state=finished raised TypeError>]
2025-11-28 09:33:18,009 [INFO] modules.ui.ui_interview: First question generated: 'Could not generate question. Please try again.'
2025-11-28 09:44:45,337 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:44:45,398 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-11-28 09:44:47,804 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 09:44:47,805 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you faced a challenge while working on a team project and how you contributed to overcoming it?'
2025-11-28 11:28:12,024 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:34:46,264 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Software Engineer
2025-11-28 11:34:49,048 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:34:51,366 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:34:51,375 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you faced a challenge while working on a project and how you overcame it?'
2025-11-28 11:35:08,484 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Eingener
2025-11-28 11:35:11,175 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:35:11,176 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Clarification needed: The job title "Eingener" appears to be misspelled or unclear. It may be intended to refer to "Engineer," "Designer," or another specific role. Please clarify what you meant by "Eingener."
2025-11-28 11:35:21,152 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:35:28,676 [INFO] modules.ui.ui_sidebar: User requesting restart with job_title=Eingener
2025-11-28 11:35:31,764 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:35:31,766 [INFO] modules.ui.ui_sidebar: Job title needs clarification: Clarification needed: The job title "Eingener" appears to be misspelled or unclear. It may be intended to refer to "Engineer" or another specific role. Please clarify what you mean, such as:

1. Engineer (e.g., Software Engineer, Civil Engineer)
2. Designer (e.g., Graphic Designer, Product Designer)
3. Any other specific role you had in mind.
2025-11-28 11:35:40,736 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:36:37,326 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:36:37,399 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Baker
2025-11-28 11:36:40,966 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:36:40,967 [INFO] modules.ui.ui_interview: First question generated: 'What techniques do you use to ensure consistent dough fermentation and how do you adjust your process for different types of bread?'
2025-11-28 11:37:16,080 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:37:18,497 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:38:09,932 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:38:12,281 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:39:58,926 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:40:01,314 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:40:17,711 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:40:20,137 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:40:45,135 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:40:47,731 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:41:19,733 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:41:22,657 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:56:45,590 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:56:45,667 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Dispatcher
2025-11-28 11:56:48,040 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:56:48,041 [INFO] modules.ui.ui_interview: First question generated: 'How do you prioritize multiple urgent requests from different clients while ensuring timely communication and service delivery?'
2025-11-28 11:57:30,866 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:57:33,177 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:58:34,789 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:58:37,169 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:59:15,837 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:59:18,258 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:59:49,753 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 11:59:52,035 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 12:00:09,125 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 12:00:11,496 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 12:01:57,575 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:02:05,134 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:02:24,805 [INFO] modules.ui.ui_start_screen: Interview started after clarification: construction joiner
2025-11-28 14:02:27,875 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:02:27,890 [INFO] modules.ui.ui_interview: First question generated: "Can you describe a time when you had to work closely with a team to complete a construction project? What was your role and how did you contribute to the team's success?"
2025-11-28 14:02:52,859 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:02:55,175 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:03:48,020 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:03:50,891 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:04:03,182 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:04:05,690 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:04:30,309 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:04:32,712 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:04:54,676 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:04:57,063 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:06:46,583 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:06:46,668 [INFO] modules.ui.ui_start_screen: Interview started for job_title=carpenter joiner
2025-11-28 14:06:49,852 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:06:49,854 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to work closely with a client to understand their vision for a project? How did you ensure their needs were met?'
2025-11-28 14:06:59,894 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:07:02,302 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:07:51,800 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-11-28 14:07:54,417 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 09:52:11,794 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 09:52:11,890 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Baker
2025-12-01 09:52:15,003 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 09:52:15,005 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to adjust a recipe or baking technique to accommodate a specific dietary restriction or customer request? What steps did you take to ensure the final product met quality standards?'
2025-12-01 09:52:54,445 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 09:52:57,523 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:25:17,647 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:25:17,650 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=validation/base_instructions.j2, technique=validate_job_title.j2
2025-12-01 10:25:17,650 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:25:17,650 [ERROR] modules.utils: Failed to load template 'validation/validation/base_instructions.j2': 'validation/validation/base_instructions.j2' not found in search path: 'C:\\Users\\thoma\\Desktop\\SAE\\knowledge-by-module\\modules\\M2_Sprint1\\interview_practice_app\\prompts'
2025-12-01 10:26:36,288 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:26:36,290 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 10:26:36,290 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:26:36,292 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:26:39,924 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:26:39,999 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-12-01 10:26:40,078 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:26:40,080 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 10:26:40,080 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:26:40,081 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:26:42,752 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:26:42,753 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to work closely with a team to solve a technical problem? What role did you play in the collaboration?'
2025-12-01 10:27:09,838 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:27:09,838 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 10:27:09,838 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:27:09,849 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:27:12,582 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:27:12,586 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:27:12,586 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 10:27:12,586 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:27:12,586 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: <class 'pathlib.Path'>
2025-12-01 10:27:14,983 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:33:25,900 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 10:33:25,903 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\job_title_validator.j2
2025-12-01 10:33:25,903 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 10:33:25,903 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 10:33:25,904 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\validation\base_instructions.j2
2025-12-01 10:33:25,904 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 10:33:25,906 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\validation\validate_job_title.j2
2025-12-01 10:33:29,237 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:33:29,308 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-12-01 10:33:29,403 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 10:33:29,405 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\eval_and_question.j2
2025-12-01 10:33:29,405 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 10:33:29,405 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 10:33:29,406 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\base_instructions.j2
2025-12-01 10:33:29,406 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 10:33:29,408 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\contextual_progression.j2
2025-12-01 10:33:31,747 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:33:31,749 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to advocate for a technical solution that was initially met with resistance from your team? How did you approach the situation and what was the outcome?'
2025-12-01 10:34:38,055 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 10:34:38,055 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\eval_and_question.j2
2025-12-01 10:34:38,055 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 10:34:38,056 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 10:34:38,057 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\evaluation\base_instructions.j2
2025-12-01 10:34:38,057 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 10:34:38,059 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\evaluation\personality_hiring_manager.j2
2025-12-01 10:34:40,597 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 10:34:40,599 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 10:34:40,600 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\eval_and_question.j2
2025-12-01 10:34:40,600 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 10:34:40,600 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 10:34:40,600 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\base_instructions.j2
2025-12-01 10:34:40,600 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 10:34:40,600 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\contextual_progression.j2
2025-12-01 10:34:43,427 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:13:16,762 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 13:13:16,765 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\job_title_validator.j2
2025-12-01 13:13:16,765 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 13:13:16,765 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 13:13:16,767 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\validation\base_instructions.j2
2025-12-01 13:13:16,767 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 13:13:16,769 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\validation\validate_job_title.j2
2025-12-01 13:13:20,335 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:13:20,418 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-12-01 13:13:20,502 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:13:20,503 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\eval_and_question.j2
2025-12-01 13:13:20,503 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:13:20,504 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:13:20,505 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\base_instructions.j2
2025-12-01 13:13:20,505 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:13:20,506 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\contextual_progression.j2
2025-12-01 13:13:23,230 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:13:23,231 [INFO] modules.ui.ui_interview: First question generated: 'Can you explain how you would optimize a slow-performing SQL query? Please describe the steps you would take and any tools or techniques you might use.'
2025-12-01 13:15:10,493 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:15:10,493 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\eval_and_question.j2
2025-12-01 13:15:10,493 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 13:15:10,493 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 13:15:10,496 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\evaluation\base_instructions.j2
2025-12-01 13:15:10,496 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 13:15:10,497 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\evaluation\personality_hiring_manager.j2
2025-12-01 13:15:10,552 [INFO] modules.interview_logic: [DEBUG] User answer:
I would start by analyzing the query execution plan to identify bottlenecks and expensive operations. Next, Id consider adding indexes, rewriting joins or subqueries, and ensuring proper use of filtering and aggregation to reduce data scanned. Id also use profiling tools like EXPLAIN or SQL Server Profiler to measure improvements and iteratively refine the query for better performance.
2025-12-01 13:15:10,555 [INFO] modules.interview_logic: [DEBUG] User answer:
I would start by analyzing the query execution plan to identify bottlenecks and expensive operations. Next, Id consider adding indexes, rewriting joins or subqueries, and ensuring proper use of filtering and aggregation to reduce data scanned. Id also use profiling tools like EXPLAIN or SQL Server Profiler to measure improvements and iteratively refine the query for better performance.
2025-12-01 13:15:13,468 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:15:13,469 [INFO] modules.interview_logic: [DEBUG] Raw model response: {"feedback":"Your answer is too brief. Please elaborate with specific examples, context, and details relevant to 'What strategies do you use to manage conflicts within a team?'.","next_question":null}
2025-12-01 13:15:13,469 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:15:13,470 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\system\eval_and_question.j2
2025-12-01 13:15:13,470 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:15:13,470 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:15:13,470 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\base_instructions.j2
2025-12-01 13:15:13,471 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:15:13,471 [INFO] modules.utils: [PROMPT LOADER] Resolved template file: C:\Users\thoma\Desktop\SAE\knowledge-by-module\modules\M2_Sprint1\interview_practice_app\prompts\questions\contextual_progression.j2
2025-12-01 13:15:16,186 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:27:49,420 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 13:27:49,424 [INFO] modules.utils: [DEBUG] Rendered template preview: You are an assistant responsible for validating job titles provided by users.

Your task is to:
- determine whether the job title is valid and commonly recognized,
- detect ambiguous or unclear entries,
- request clarification when necessary.

Always respond clearly and concisely. Do not create job titles that do not exist.
Do not assume meanings that are not supported by the input.
2025-12-01 13:27:49,424 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 13:27:49,424 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 13:27:49,425 [INFO] modules.utils: [DEBUG] Rendered template preview: You will receive a job title that the user intends to use for an interview simulation.

Your responsibilities:
1. Assess whether the job title is specific and recognizable.
2. Identify titles that are too broad, vague, misspelled, or incomplete.
3. Decide whether clarification is required.

A job title is considered valid when:
- it corresponds to an established professional role,
- it is specific enough to guide an interview scenario,
- it is not simply a domain, industry, or skill area.

If th
2025-12-01 13:27:49,425 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 13:27:49,427 [INFO] modules.utils: [DEBUG] Rendered template preview: Evaluate the following job title:

"Joiner"

Determine:
- whether it is a valid, specific job title,
- or whether clarification is required.

If clarification is needed, start your response with:
"Clarification needed:"

Otherwise, confirm that the title is valid.
2025-12-01 13:27:57,013 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:28:05,699 [INFO] modules.ui.ui_start_screen: Interview started after clarification: Furniture Joiner
2025-12-01 13:28:05,798 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:28:05,800 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:28:05,800 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:28:05,801 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:28:05,808 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:28:05,810 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Furniture Joiner
Question Type: Behavioral
Difficulty: Easy
Previous Answers Summary: []


# Contextual Progression Technique
Using previous answers as soft context, generate a question that builds logically from them while staying aligned with the selected difficulty and type. Do not reference previous answers explicitly.
Output ONLY the question.

2025-12-01 13:28:09,460 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:28:09,469 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to collaborate with a team to complete a furniture project? What role did you play, and how did you ensure effective communication throughout the process?'
2025-12-01 13:28:34,986 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:28:34,987 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:28:34,987 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 13:28:34,987 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 13:28:34,989 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Evaluation Base Instructions (Shared Across All Personas)

You will evaluate the candidate's most recent answer.

VARIABLES AVAILABLE:
- Current question: {{ question }}
- Candidate's answer: {{ answer }}
- Previous answers: {% for ans in previous_answers %}{{ loop.index }}. {{ ans }}{% if not loop.last %}\n{% endif %}{% endfor %}
- Job title: {{ job_title }}
- Question type: {{ question_type }}
- Difficulty: {{ difficulty }}

ANSWER QUALITY DETECTION:
First, categorize the answer quality usi
2025-12-01 13:28:34,989 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 13:28:34,990 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Hiring Manager Evaluation Mode

You are evaluating the candidate as a *pragmatic, business-oriented hiring manager*.
Your goal is to judge whether this person can perform the real job.

Tone:
- Direct, practical, no-nonsense.
- Focus on value, outcomes, clarity, and ownership.
- Avoid corporate fluff.

Structure Your Evaluation:
1. **What impressed me (from a managers perspective)**
2. **Where this answer concerns me**
3. **Impact on job performance**
4. **Actionable advice for improvement**
2025-12-01 13:28:34,993 [INFO] modules.interview_logic: [DEBUG] User answer:
I worked with a team to build custom cabinets for a client, where each member was responsible for different stages of cutting, assembly, and finishing. I coordinated the workflow, kept track of progress, and regularly updated the team on measurements and design adjustments to ensure everyone stayed aligned. By holding short check-ins and documenting key decisions, we completed the project efficiently and delivered a high-quality product that matched the clients vision.
2025-12-01 13:28:34,994 [DEBUG] modules.interview_logic: === LLM CALL START ===
2025-12-01 13:28:35,001 [DEBUG] modules.interview_logic: Structured Output Schema:
{'format': {'type': 'json_schema', 'name': 'evaluation_result', 'strict': True, 'schema': {'type': 'object', 'properties': {'feedback': {'type': 'string'}, 'next_question': {'type': ['string', 'null']}}, 'required': ['feedback', 'next_question'], 'additionalProperties': False}}}
2025-12-01 13:28:35,001 [DEBUG] modules.interview_logic: === Sending request to OpenAI ===
2025-12-01 13:28:35,005 [INFO] modules.interview_logic: [DEBUG] User answer:
I worked with a team to build custom cabinets for a client, where each member was responsible for different stages of cutting, assembly, and finishing. I coordinated the workflow, kept track of progress, and regularly updated the team on measurements and design adjustments to ensure everyone stayed aligned. By holding short check-ins and documenting key decisions, we completed the project efficiently and delivered a high-quality product that matched the clients vision.
2025-12-01 13:28:38,689 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:28:38,694 [DEBUG] modules.interview_logic: === LLM CALL END  Raw Response Below ===
2025-12-01 13:28:38,694 [INFO] modules.interview_logic: [DEBUG] Raw model response: {"feedback":"Your answer is too brief. Please elaborate with specific examples, context, and details relevant to 'What strategies do you use to manage conflicts within a team?'.","next_question":null}
2025-12-01 13:28:38,694 [DEBUG] modules.interview_logic: === END OF RESPONSE ===
2025-12-01 13:28:38,694 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:28:38,695 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:28:38,695 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:28:38,696 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:28:38,700 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:28:38,700 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Furniture Joiner
Question Type: Behavioral
Difficulty: Easy
Previous Answers Summary: []


# Contextual Progression Technique
Using previous answers as soft context, generate a question that builds logically from them while staying aligned with the selected difficulty and type. Do not reference previous answers explicitly.
Output ONLY the question.

2025-12-01 13:28:41,173 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:32:44,914 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:32:44,914 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:32:44,914 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 13:32:44,915 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 13:32:44,915 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Evaluation Base Instructions (Shared Across All Personas)

You will evaluate the candidate's most recent answer.

VARIABLES AVAILABLE:
- Current question: {{ question }}
- Candidate's answer: {{ answer }}
- Previous answers: {% for ans in previous_answers %}{{ loop.index }}. {{ ans }}{% if not loop.last %}\n{% endif %}{% endfor %}
- Job title: {{ job_title }}
- Question type: {{ question_type }}
- Difficulty: {{ difficulty }}

ANSWER QUALITY DETECTION:
First, categorize the answer quality usi
2025-12-01 13:32:44,915 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 13:32:44,915 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Hiring Manager Evaluation Mode

You are evaluating the candidate as a *pragmatic, business-oriented hiring manager*.
Your goal is to judge whether this person can perform the real job.

Tone:
- Direct, practical, no-nonsense.
- Focus on value, outcomes, clarity, and ownership.
- Avoid corporate fluff.

Structure Your Evaluation:
1. **What impressed me (from a managers perspective)**
2. **Where this answer concerns me**
3. **Impact on job performance**
4. **Actionable advice for improvement**
2025-12-01 13:32:44,920 [INFO] modules.interview_logic: [DEBUG] User answer:
I worked with a team to build custom furniture for a client, where each member was responsible for different stages like cutting, assembly, and finishing. My role was to coordinate the workflow, track progress, and ensure everyone had the latest measurements and design updates. I held short daily check-ins and documented key decisions so that all team members stayed aligned, which helped us complete the project efficiently and deliver a high-quality final product.
2025-12-01 13:32:44,920 [DEBUG] modules.interview_logic: === LLM CALL START ===
2025-12-01 13:32:44,929 [DEBUG] modules.interview_logic: Structured Output Schema:
{'format': {'type': 'json_schema', 'name': 'evaluation_result', 'strict': True, 'schema': {'type': 'object', 'properties': {'feedback': {'type': 'string'}, 'next_question': {'type': ['string', 'null']}}, 'required': ['feedback', 'next_question'], 'additionalProperties': False}}}
2025-12-01 13:32:44,929 [DEBUG] modules.interview_logic: === Sending request to OpenAI ===
2025-12-01 13:32:44,933 [INFO] modules.interview_logic: [DEBUG] User answer:
I worked with a team to build custom furniture for a client, where each member was responsible for different stages like cutting, assembly, and finishing. My role was to coordinate the workflow, track progress, and ensure everyone had the latest measurements and design updates. I held short daily check-ins and documented key decisions so that all team members stayed aligned, which helped us complete the project efficiently and deliver a high-quality final product.
2025-12-01 13:32:47,362 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:32:47,364 [DEBUG] modules.interview_logic: === LLM CALL END  Raw Response Below ===
2025-12-01 13:32:47,364 [INFO] modules.interview_logic: [DEBUG] Raw model response: {"feedback":"Your answer is too brief. Please elaborate with specific examples, context, and details relevant to 'What is your approach to managing a team under tight deadlines?'.","next_question":null}
2025-12-01 13:32:47,364 [DEBUG] modules.interview_logic: === END OF RESPONSE ===
2025-12-01 13:32:47,364 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:32:47,364 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:32:47,365 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:32:47,365 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:32:47,368 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:32:47,368 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Furniture Joiner
Question Type: Behavioral
Difficulty: Easy
Previous Answers Summary: ['I worked with a team to build custom cabinets for a client, where each member was responsible for different stages of cutting, assembly, and finishing. I coordinated the workflow, kept track of progress, and regularly updated the team on measurements and design adjustments to ensure everyone stayed aligned. By holding short check-ins and documenting key decisions, we completed the project efficient
2025-12-01 13:32:49,676 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:51:16,544 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 13:51:16,547 [INFO] modules.utils: [DEBUG] Rendered template preview: You are an assistant responsible for validating job titles provided by users.

Your task is to:
- determine whether the job title is valid and commonly recognized,
- detect ambiguous or unclear entries,
- request clarification when necessary.

Always respond clearly and concisely. Do not create job titles that do not exist.
Do not assume meanings that are not supported by the input.
2025-12-01 13:51:16,547 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 13:51:16,548 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 13:51:16,549 [INFO] modules.utils: [DEBUG] Rendered template preview: You will receive a job title that the user intends to use for an interview simulation.

Your responsibilities:
1. Assess whether the job title is specific and recognizable.
2. Identify titles that are too broad, vague, misspelled, or incomplete.
3. Decide whether clarification is required.

A job title is considered valid when:
- it corresponds to an established professional role,
- it is specific enough to guide an interview scenario,
- it is not simply a domain, industry, or skill area.

If th
2025-12-01 13:51:16,549 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 13:51:16,550 [INFO] modules.utils: [DEBUG] Rendered template preview: Evaluate the following job title:

"Software Engineer"

Determine:
- whether it is a valid, specific job title,
- or whether clarification is required.

If clarification is needed, start your response with:
"Clarification needed:"

Otherwise, confirm that the title is valid.
2025-12-01 13:51:20,225 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:51:20,301 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-12-01 13:51:20,372 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:51:20,373 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:51:20,374 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:51:20,374 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:51:20,382 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:51:20,384 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Software Engineer
Question Type: Role-specific
Difficulty: Easy
Previous Answers Summary: []


# Contextual Progression Technique
Using previous answers as soft context, generate a question that builds logically from them while staying aligned with the selected difficulty and type. Do not reference previous answers explicitly.
Output ONLY the question.

2025-12-01 13:51:22,685 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:51:22,687 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to debug a complex issue in your code? What steps did you take to identify and resolve the problem?'
2025-12-01 13:51:41,088 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:51:41,088 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:51:41,090 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 13:51:41,090 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 13:51:41,091 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Evaluation Base Instructions (Shared Across All Personas)

You will evaluate the candidate's most recent answer.

VARIABLES AVAILABLE:
- Current question: {{ question }}
- Candidate's answer: {{ answer }}
- Previous answers: {% for ans in previous_answers %}{{ loop.index }}. {{ ans }}{% if not loop.last %}\n{% endif %}{% endfor %}
- Job title: {{ job_title }}
- Question type: {{ question_type }}
- Difficulty: {{ difficulty }}

ANSWER QUALITY DETECTION:
First, categorize the answer quality usi
2025-12-01 13:51:41,093 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 13:51:41,094 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Hiring Manager Evaluation Mode

You are evaluating the candidate as a *pragmatic, business-oriented hiring manager*.
Your goal is to judge whether this person can perform the real job.

Tone:
- Direct, practical, no-nonsense.
- Focus on value, outcomes, clarity, and ownership.
- Avoid corporate fluff.

Structure Your Evaluation:
1. **What impressed me (from a managers perspective)**
2. **Where this answer concerns me**
3. **Impact on job performance**
4. **Actionable advice for improvement**
2025-12-01 13:51:41,098 [INFO] modules.interview_logic: [DEBUG] User answer:
I encountered a complex bug in a program where a function intermittently returned incorrect results. I first reproduced the issue consistently, then used logging and step-by-step debugging to trace the problem to a specific section of code with an edge-case I hadnt handled. After identifying the root cause, I refactored the logic, added unit tests for similar cases, and verified the fix, ensuring the program behaved correctly in all scenarios.
2025-12-01 13:51:41,098 [DEBUG] modules.interview_logic: === LLM CALL START ===
2025-12-01 13:51:41,107 [DEBUG] modules.interview_logic: Structured Output Schema:
{'format': {'type': 'json_schema', 'name': 'evaluation_result', 'strict': True, 'schema': {'type': 'object', 'properties': {'feedback': {'type': 'string'}, 'next_question': {'type': ['string', 'null']}}, 'required': ['feedback', 'next_question'], 'additionalProperties': False}}}
2025-12-01 13:51:41,107 [DEBUG] modules.interview_logic: === Sending request to OpenAI ===
2025-12-01 13:51:41,110 [INFO] modules.interview_logic: [DEBUG] User answer:
I encountered a complex bug in a program where a function intermittently returned incorrect results. I first reproduced the issue consistently, then used logging and step-by-step debugging to trace the problem to a specific section of code with an edge-case I hadnt handled. After identifying the root cause, I refactored the logic, added unit tests for similar cases, and verified the fix, ensuring the program behaved correctly in all scenarios.
2025-12-01 13:51:43,503 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 13:51:43,507 [DEBUG] modules.interview_logic: === LLM CALL END  Raw Response Below ===
2025-12-01 13:51:43,507 [INFO] modules.interview_logic: [DEBUG] Raw model response: {"feedback":"Your answer is too brief. Please elaborate with specific examples, context, and details relevant to 'What strategies do you use to manage your time effectively when working on multiple projects?'.","next_question":null}
2025-12-01 13:51:43,508 [DEBUG] modules.interview_logic: === END OF RESPONSE ===
2025-12-01 13:51:43,508 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 13:51:43,508 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 13:51:43,510 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 13:51:43,510 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 13:51:43,516 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 13:51:43,516 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Software Engineer
Question Type: Role-specific
Difficulty: Easy
Previous Answers Summary: []


# Contextual Progression Technique
Using previous answers as soft context, generate a question that builds logically from them while staying aligned with the selected difficulty and type. Do not reference previous answers explicitly.
Output ONLY the question.

2025-12-01 13:51:46,575 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:31:30,463 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 14:31:30,465 [INFO] modules.utils: [DEBUG] Rendered template preview: You are an assistant responsible for validating job titles provided by users.

Your task is to:
- determine whether the job title is valid and commonly recognized,
- detect ambiguous or unclear entries,
- request clarification when necessary.

Always respond clearly and concisely. Do not create job titles that do not exist.
Do not assume meanings that are not supported by the input.
2025-12-01 14:31:30,466 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 14:31:30,466 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 14:31:30,468 [INFO] modules.utils: [DEBUG] Rendered template preview: You will receive a job title that the user intends to use for an interview simulation.

Your responsibilities:
1. Assess whether the job title is specific and recognizable.
2. Identify titles that are too broad, vague, misspelled, or incomplete.
3. Decide whether clarification is required.

A job title is considered valid when:
- it corresponds to an established professional role,
- it is specific enough to guide an interview scenario,
- it is not simply a domain, industry, or skill area.

If th
2025-12-01 14:31:30,469 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 14:31:30,470 [INFO] modules.utils: [DEBUG] Rendered template preview: Evaluate the following job title:

"Software Engineer"

Determine:
- whether it is a valid, specific job title,
- or whether clarification is required.

If clarification is needed, start your response with:
"Clarification needed:"

Otherwise, confirm that the title is valid.
2025-12-01 14:31:33,887 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:31:33,966 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-12-01 14:31:34,056 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:31:34,057 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 14:31:34,059 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:31:34,059 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:31:34,070 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:31:34,072 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Software Engineer
Question Type: Behavioral
Difficulty: Hard
Previous Answers Summary: []


# Contextual Progression Technique
Using previous answers as soft context, generate a question that builds logically from them while staying aligned with the selected difficulty and type. Do not reference previous answers explicitly.
Output ONLY the question.

2025-12-01 14:31:36,906 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:31:36,908 [INFO] modules.ui.ui_interview: First question generated: 'Can you describe a time when you had to advocate for a technical solution that was initially met with resistance from your team? How did you approach the situation and what was the outcome?'
2025-12-01 14:32:24,463 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:32:24,463 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 14:32:24,465 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 14:32:24,465 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 14:32:24,467 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Evaluation Base Instructions (Shared Across All Personas)

You will evaluate the candidate's most recent answer.

VARIABLES AVAILABLE:
- Current question: {{ question }}
- Candidate's answer: {{ answer }}
- Previous answers: {% for ans in previous_answers %}{{ loop.index }}. {{ ans }}{% if not loop.last %}\n{% endif %}{% endfor %}
- Job title: {{ job_title }}
- Question type: {{ question_type }}
- Difficulty: {{ difficulty }}

ANSWER QUALITY DETECTION:
First, categorize the answer quality usi
2025-12-01 14:32:24,468 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 14:32:24,469 [INFO] modules.utils: [DEBUG] Rendered template preview: 
# Hiring Manager Evaluation Mode

You are evaluating the candidate as a *pragmatic, business-oriented hiring manager*.
Your goal is to judge whether this person can perform the real job.

Tone:
- Direct, practical, no-nonsense.
- Focus on value, outcomes, clarity, and ownership.
- Avoid corporate fluff.

Structure Your Evaluation:
1. **What impressed me (from a managers perspective)**
2. **Where this answer concerns me**
3. **Impact on job performance**
4. **Actionable advice for improvement**
2025-12-01 14:32:24,475 [INFO] modules.interview_logic: [DEBUG] User answer:
I encountered a complex bug in a program where a function intermittently returned incorrect results. I first reproduced the issue consistently, then used logging and step-by-step debugging to trace the problem to a specific section of code with an edge-case I hadnt handled. After identifying the root cause, I refactored the logic, added unit tests for similar cases, and verified the fix, ensuring the program behaved correctly in all scenarios
2025-12-01 14:32:24,475 [DEBUG] modules.interview_logic: === LLM CALL START ===
2025-12-01 14:32:24,483 [DEBUG] modules.interview_logic: Structured Output Schema:
{'format': {'type': 'json_schema', 'name': 'evaluation_result', 'strict': True, 'schema': {'type': 'object', 'properties': {'feedback': {'type': 'string'}, 'next_question': {'type': ['string', 'null']}}, 'required': ['feedback', 'next_question'], 'additionalProperties': False}}}
2025-12-01 14:32:24,483 [DEBUG] modules.interview_logic: === Sending request to OpenAI ===
2025-12-01 14:32:24,487 [INFO] modules.interview_logic: [DEBUG] User answer:
I encountered a complex bug in a program where a function intermittently returned incorrect results. I first reproduced the issue consistently, then used logging and step-by-step debugging to trace the problem to a specific section of code with an edge-case I hadnt handled. After identifying the root cause, I refactored the logic, added unit tests for similar cases, and verified the fix, ensuring the program behaved correctly in all scenarios
2025-12-01 14:32:26,965 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:32:26,967 [DEBUG] modules.interview_logic: === LLM CALL END  Raw Response Below ===
2025-12-01 14:32:26,967 [INFO] modules.interview_logic: [DEBUG] Raw model response: {"feedback":"Your answer is too brief. Please elaborate with specific examples, context, and details relevant to 'What strategies do you use to ensure effective communication within your team?'.","next_question":null}
2025-12-01 14:32:26,968 [DEBUG] modules.interview_logic: === END OF RESPONSE ===
2025-12-01 14:32:26,968 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:32:26,968 [INFO] modules.utils: [DEBUG] Rendered template preview: 
You are the Interview Engine.

Your job depends on the mode passed into the prompt:

============================================================
MODE 1: "generate_question"
============================================================

You generate **ONE** interview question that:
- matches the job title
- matches the selected difficulty
- matches the user's chosen question type
- explores a DIFFERENT competency area than previous questions
- avoids repetition of themes, scenarios, or phrasings
2025-12-01 14:32:26,969 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:32:26,969 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:32:26,975 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:32:26,976 [INFO] modules.utils: [DEBUG] Rendered template preview: Job Title: Software Engineer
Question Type: Behavioral
Difficulty: Hard
Previous Answers Summary: []


# Contextual Progression Technique
Using previous answers as soft context, generate a question that builds logically from them while staying aligned with the selected difficulty and type. Do not reference previous answers explicitly.
Output ONLY the question.

2025-12-01 14:32:29,270 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:41:39,107 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 14:41:39,110 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 14:41:39,110 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 14:41:39,111 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 14:41:41,934 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:41:42,024 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Dispatcher
2025-12-01 14:41:42,097 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:41:42,098 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:41:42,098 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:41:42,099 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:41:44,526 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:41:44,530 [INFO] modules.ui.ui_interview: First question generated: 'Describe a time when you had to manage multiple urgent requests simultaneously as a dispatcher. How did you prioritize the tasks and ensure effective communication with your team and clients?'
2025-12-01 14:42:17,374 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:42:17,375 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 14:42:17,375 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 14:42:17,377 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 14:42:17,384 [INFO] modules.interview_logic: [DEBUG] User answer:
"In one shift, I received several urgent calls requiring immediate attention, including emergency pickups and critical deliveries. I quickly assessed each request's urgency, coordinated with team members based on their location and availability, and used a shared communication system to keep everyone updated. By staying organized, delegating efficiently, and maintaining clear communication with clients, all tasks were completed on time without errors.
2025-12-01 14:42:19,949 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:42:19,950 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:42:19,951 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:42:19,951 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:42:19,951 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:42:22,383 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:49:58,208 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 14:51:22,273 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/job_title_validator.j2
2025-12-01 14:51:22,276 [INFO] modules.utils: [PROMPT BUILDER] category=validation, base=base_instructions.j2, technique=validate_job_title.j2
2025-12-01 14:51:22,276 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/base_instructions.j2
2025-12-01 14:51:22,278 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: validation/validate_job_title.j2
2025-12-01 14:51:25,608 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:51:25,688 [INFO] modules.ui.ui_start_screen: Interview started for job_title=Software Engineer
2025-12-01 14:51:25,760 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:51:25,762 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:51:25,762 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:51:25,764 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:51:29,011 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:51:29,015 [INFO] modules.ui.ui_interview: First question generated: 'Describe a challenging software project you worked on where you had to integrate multiple technologies. What were the key decisions you made during the integration process, and how did you ensure the final product met the project requirements?'
2025-12-01 14:52:03,347 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:52:03,348 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 14:52:03,348 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 14:52:03,349 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 14:52:03,355 [INFO] modules.interview_logic: [DEBUG] User answer:
"I worked on a project that required integrating a web frontend, a RESTful API, and a machine learning service for real-time recommendations. I carefully evaluated technology compatibility, chose standardized data formats, and implemented modular interfaces to ensure smooth communication between components. Throughout development, I conducted frequent integration tests and code reviews to verify that all parts worked together and met the project requirements.
2025-12-01 14:52:05,918 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:52:06,191 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:52:06,191 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:52:06,192 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:52:06,192 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:52:08,806 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:56:24,863 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:56:24,865 [INFO] modules.utils: [PROMPT BUILDER] category=evaluation, base=base_instructions.j2, technique=personality_hiring_manager.j2
2025-12-01 14:56:24,865 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/base_instructions.j2
2025-12-01 14:56:24,867 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: evaluation/personality_hiring_manager.j2
2025-12-01 14:56:24,874 [INFO] modules.interview_logic: [DEBUG] User answer:
"I worked on a project that required integrating a web frontend, a RESTful API, and a machine learning service for real-time recommendations. I carefully evaluated technology compatibility, chose standardized data formats, and implemented modular interfaces to ensure smooth communication between components. Throughout development, I conducted frequent integration tests and code reviews to verify that all parts worked together and met the project requirements.
2025-12-01 14:56:27,386 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-12-01 14:56:27,389 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: system/eval_and_question.j2
2025-12-01 14:56:27,389 [INFO] modules.utils: [PROMPT BUILDER] category=questions, base=base_instructions.j2, technique=contextual_progression.j2
2025-12-01 14:56:27,389 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/base_instructions.j2
2025-12-01 14:56:27,391 [INFO] modules.utils: [PROMPT LOADER] Loading prompt template: questions/contextual_progression.j2
2025-12-01 14:56:29,801 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
